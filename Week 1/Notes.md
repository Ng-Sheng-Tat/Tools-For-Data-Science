## Week 1
1. Visual Programming Languages
2. Tools
3. Programming Languages
---
Most Common Languages Used
1. Python
2. SQL
3. R
4. Java
5. C++
6. Scala
7. Julia
---
Roles in Data Science
1. Business Analyst
2. Database Engineer
3. Data Analyst
4. Data Engineer
5. Data Scientist
6. Research Scientist
7. Software Engineer
8. Statistician
9. Product Manager
10. Project Manager
11. etc
---
**Tasks for Data Science**
1. Data Management (MySQL, PostgrateSQL, mongoDB, hadoop HDFS, couchDB, cassandra, ceph, elastic search)
  - Oracle Database, SQL Server, IBM DB2
  - Amazon DynamoDB, Cloudant (CouchDB)
2. Data Integration and Transformation (Extract Transform and Load, ETL or Data Refining and Cleaning), (Apache Airflow, Apache Kafka, Spark SQL, Kubeflow, Apache nifi, NODE-RED)
  - Talend, IBM InfoSphere DataStage, Informatica, IBM Watson Studio Desktop
  - Informatica, IBM Data Refinery
3. Data Visualization (HUE, Kibana, Superset)
  - Tableau, Power BI, IBM Cognos Analytics, IBM Watson Studio Desktop
  - Datameer, IBM Cognos Analytics, Watson Studio
4. Model Building
  - SPSS, SAS, IBM Watson Studio
  - Google Cloud, IBM Watson Machine Learning
5. Model Deployment (prediction IO, mleap, Tensorflow Service (TensorflowLite, Tensorflow.js), Seldom)
  - IBM SPSS
6. Model Monitoring and Assessment (ModelDB, Prometheus, AI Fairness 360 Open Source Toolkit, Adversarial Robustness 360 Toolbox, AI Explainability 360)
  - Amazon SageMaker Model Monitor, Watson OpenScale
7. Fully Integrated Visual Tools
8. Execution Environment (Apache Spark, Apache Flink, Riselab Ray)
9. Data Asset Management (Apache Atlas, ODP EGERIA, KYIO)
  - Informatica, IBM InfoSphere, IBM Watson Studio Desktop, Watson OpenScale, H2O , Microsoft Azure
10. Code Asset Management (Version Control, Git, Github, Gitlab, Bitbucket )
11. Development Environments (Jupyter, JupyterLab, Zeppelin, RStudio, Spyder)
**KNIME and Orange** provides visual interface
---
**Libraries for Data Science**
1. Scientific Computing Library - pandas, numpy
2. Visualization Library - matplotlib, seaborn
3. Machine Learning Library - scikit-learn, keras, Tensorflow, Pytorch
- Apache Spark for general integrated purpose
- vegas (in scala), bigdl (in scala), ggplot2 (R)
- **API** is the interface for communication
- **REpresentational State Transfer (REST)**
---
**Data Structures**
1. Tabular
2. Hierarchical data, network data
3. Raw files
---
**Open Data**
1. Kaggle
2. datasetsearch
3. governmental data
4. Data Asset eXchange (DAX)
---
**Machine Learning and Deep Learning Model**
- trained before being used for prediction
- supervised learning, learn by labelled data (Prediction and classification)
- unsupervised learning, learn by unlabelled data (Clustering and Anomaly Detection)
- reinforcement learning, learn by rewards (used in games)
- deep learning learn by neural network (time series fore casting, image, audio, video analysis, NLP), used pretrained one using Keras, PyTorch, TensorFlow
**Workflow**
Preparedata -> Build model -> Trainmodel and iterate to compare -> Deploy model -> Use model
**Pre-trained model by IBM** MAX model-serving microservice (Docker), Model Asset eXchange
